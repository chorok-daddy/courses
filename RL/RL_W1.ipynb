{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMeTeqB+iYBug6bY7QurdRG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 1주차: 강화학습 소개"],"metadata":{"id":"SNeHgFKxLUnL"}},{"cell_type":"markdown","source":["## [강화학습이란?]"],"metadata":{"id":"DoO636THMTJr"}},{"cell_type":"markdown","source":["### 1. 정의\n","\n","* 에이전트(Agent)가 환경(Environment)과 상호작용하며 보상(Reward)을 최대화하는 정책(Policy)을 학습하는 기계학습 분야\n","\n"],"metadata":{"id":"YCeCnuTKMGSj"}},{"cell_type":"markdown","source":["### 2. 주요 구성 요소\n","\n","* **에이전트 (Agent)**\n","    * 정책(Policy)에 따라 행동(Action)을 선택하는 주체\n","* **환경 (Environment)**\n","    * 에이전트의 행동을 받아 다음 상태(State)와 보상(Reward)을 반환하는 외부 세계\n","* **상태 (State)**\n","    * 환경이 현재 상황을 묘사하는 정보\n","        * 예시: CartPole 환경에서 카트의 위치와 막대의 기울기\n","* **행동 (Action)**\n","    * 에이전트가 환경에 취할 수 있는 선택\n","        * 예시: 카트를 왼쪽 또는 오른쪽으로 이동\n","* **보상 (Reward)**\n","    * 행동의 결과로 환경으로부터 받는 실수 값 신호\n","    * 목표: 이 보상을 최대화하는 방향으로 정책을 개선\n","* **정책 (Policy)**\n","    * 정의: 주어진 상태에서 어떤 행동을 취할지 결정하는 전략\n","    * 확률론적 정책: π(a|s)는 상태 s에서 행동 a를 선택할 확률을 의미"],"metadata":{"id":"K4y-u6qbMi2G"}},{"cell_type":"markdown","source":["### 3. 강화학습의 목표\n","\n","* 정의: 누적 보상(Return)의 기대값을 최대화하는 정책을 찾는 것\n","* 학습 과정\n","    * 환경 초기화 및 상태 수신\n","    * 행동 수행\n","    * 다음 상태와 보상 획득\n","    * 에피소드 구성 및 반복\n","    * 정책 점진적 개선\n"],"metadata":{"id":"I1dEZRhZMlOT"}},{"cell_type":"markdown","source":["### 4. 정책(Policy)\n","\n","* 정의: 주어진 상태에서 어떤 행동을 취할지 결정하는 전략\n","* 특징: 상태를 입력받아 행동의 확률 분포를 출력\n","* 확률론적 정책: π(a|s)는 상태 s에서 행동 a를 선택할 확률을 의미\n"],"metadata":{"id":"P53fN9IeMdok"}},{"cell_type":"markdown","source":["### 5. 개발 환경 설정 (Google Colab 기준)\n","\n","* 특징: 클라우드 기반 Jupyter 노트북 환경\n","* 장점: 별도의 설정 없이 PyTorch와 OpenAI Gym 사용 가능"],"metadata":{"id":"-le9mb_FMn8c"}},{"cell_type":"markdown","source":["## [실습1: PyTorch 텐서 기본 사용법]\n","\n","### 1. 텐서 생성"],"metadata":{"id":"10uOF-nrNfgy"}},{"cell_type":"code","source":["import torch\n","\n","x = torch.tensor([1.0, 2.0, 3.0])\n","print(x)"],"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 2., 3.])\n"]}],"execution_count":4,"metadata":{"id":"DZ3YMdizNfgz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740656580892,"user_tz":-540,"elapsed":12,"user":{"displayName":"Ki-Baek Lee","userId":"00357310680332321506"}},"outputId":"33ab82b2-3b21-4f40-ac06-1d4e547a6659"}},{"cell_type":"markdown","source":["### 2. 텐서 연산"],"metadata":{"id":"EBfrjgpDNfgz"}},{"cell_type":"code","source":["y = x + 2\n","print(y)"],"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([3., 4., 5.])\n"]}],"execution_count":5,"metadata":{"id":"HImQn5IcNfgz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740656584983,"user_tz":-540,"elapsed":5,"user":{"displayName":"Ki-Baek Lee","userId":"00357310680332321506"}},"outputId":"d79c2c98-88ed-4474-adaf-82877cc6c749"}},{"cell_type":"markdown","source":["### 3. 텐서의 크기 확인"],"metadata":{"id":"jqRqAmNQNfgz"}},{"cell_type":"code","source":["print(x.shape)"],"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3])\n"]}],"execution_count":6,"metadata":{"id":"vGeDWNT8Nfgz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740656590982,"user_tz":-540,"elapsed":6,"user":{"displayName":"Ki-Baek Lee","userId":"00357310680332321506"}},"outputId":"2e180f48-1d66-4e3a-e5d1-d8c9c1981a5b"}},{"cell_type":"markdown","source":["### 4. 텐서의 데이터 타입 확인"],"metadata":{"id":"LlUJtrEoNfgz"}},{"cell_type":"code","source":["print(x.dtype)"],"outputs":[{"output_type":"stream","name":"stdout","text":["torch.float32\n"]}],"execution_count":7,"metadata":{"id":"gUcfoGzZNfgz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740656595478,"user_tz":-540,"elapsed":6,"user":{"displayName":"Ki-Baek Lee","userId":"00357310680332321506"}},"outputId":"691c1273-6698-414b-9e50-b4553b177bef"}},{"cell_type":"markdown","source":["### 5. 텐서의 연산 기기 확인"],"metadata":{"id":"kCAaGvHoNfgz"}},{"cell_type":"code","source":["print(x.device)"],"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}],"execution_count":8,"metadata":{"id":"c5QBRPLYNfg0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740656604901,"user_tz":-540,"elapsed":42,"user":{"displayName":"Ki-Baek Lee","userId":"00357310680332321506"}},"outputId":"da67bb7e-6e08-4b66-96de-d295e429370e"}},{"cell_type":"markdown","source":["### 6. GPU 사용 가능 여부 확인 및 텐서 이동"],"metadata":{"id":"MqMrkvVSNfg0"}},{"cell_type":"code","source":["if torch.cuda.is_available():\n","  device = torch.device('cuda')\n","  print('GPU 사용 가능')\n","else:\n","  device = torch.device('cpu')\n","  print('GPU 사용 불가능')\n","\n","x = x.to(device)\n","print(x.device)"],"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 사용 불가능\n","cpu\n"]}],"execution_count":9,"metadata":{"id":"DkUvCZfPNfg0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740656611682,"user_tz":-540,"elapsed":7,"user":{"displayName":"Ki-Baek Lee","userId":"00357310680332321506"}},"outputId":"c4ba2e9e-99fb-46e7-9057-d116cf0cffbe"}},{"cell_type":"markdown","source":["### 7. 텐서의 요소 접근 및 변경"],"metadata":{"id":"Od3kOvNpNfg0"}},{"cell_type":"code","source":["print(x[0])\n","\n","x[0] = 10.0\n","print(x)"],"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(1.)\n","tensor([10.,  2.,  3.])\n"]}],"execution_count":10,"metadata":{"id":"vQfbGAavNfg0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740656628261,"user_tz":-540,"elapsed":11,"user":{"displayName":"Ki-Baek Lee","userId":"00357310680332321506"}},"outputId":"3d0d7858-312d-45cf-ab8b-930de8bb7e41"}},{"cell_type":"markdown","source":["### 8. 텐서의 차원 변경"],"metadata":{"id":"_mMIaQSpNfg0"}},{"cell_type":"code","source":["x = x.view(1, 3)  # (1, 3) 형태로 변환\n","print(x)\n","print(x.shape)"],"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[10.,  2.,  3.]])\n","torch.Size([1, 3])\n"]}],"execution_count":11,"metadata":{"id":"aPiX9RK-Nfg0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740656634706,"user_tz":-540,"elapsed":43,"user":{"displayName":"Ki-Baek Lee","userId":"00357310680332321506"}},"outputId":"5b99ddf1-4c03-40e8-9c0e-36a5c0ebbdb0"}},{"cell_type":"markdown","source":["### 9. 텐서의 요소 합 및 최대값"],"metadata":{"id":"BbREUuQ6Nfg0"}},{"cell_type":"code","source":["print(torch.sum(x))\n","\n","print(torch.max(x))"],"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(15.)\n","tensor(10.)\n"]}],"execution_count":12,"metadata":{"id":"FqE6YqF3Nfg0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740656642311,"user_tz":-540,"elapsed":10,"user":{"displayName":"Ki-Baek Lee","userId":"00357310680332321506"}},"outputId":"c17c9f72-b909-4e55-adff-d659d7c3c32e"}},{"cell_type":"markdown","source":["### 10. 텐서를 NumPy 배열로 변환 및 NumPy 배열을 텐서로 변환"],"metadata":{"id":"VuiwYXiNNfg0"}},{"cell_type":"code","source":["x_np = x.cpu().numpy()\n","print(x_np)\n","\n","x_tensor = torch.from_numpy(x_np)\n","print(x_tensor)"],"outputs":[{"output_type":"stream","name":"stdout","text":["[[10.  2.  3.]]\n","tensor([[10.,  2.,  3.]])\n"]}],"execution_count":13,"metadata":{"id":"tqa9PNmRNfg0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740656648725,"user_tz":-540,"elapsed":4,"user":{"displayName":"Ki-Baek Lee","userId":"00357310680332321506"}},"outputId":"5a9b0b04-f4bb-40b6-a34a-382fb2b13506"}},{"cell_type":"markdown","source":["## [실습2: CartPole-v1 환경에서 랜덤 행동 수행하기]\n","\n","* OpenAI Gym의 CartPole-v1 환경에서 에이전트가 랜덤한 행동을 수행"],"metadata":{"id":"Bu6U8snnIyZz"}},{"cell_type":"markdown","source":["### 1. 라이브러리 임포트"],"metadata":{"id":"0cucAEipOW8y"}},{"cell_type":"code","source":["import gym\n","import random"],"outputs":[],"execution_count":null,"metadata":{"id":"JB52CW3eIyZ1"}},{"cell_type":"markdown","source":["### 2. 환경 생성\n","\n","* OpenAI Gym의 `make()` 함수를 사용하여 CartPole-v1 환경을 생성"],"metadata":{"id":"ha4j0k57IyZ1"}},{"cell_type":"code","source":["env = gym.make('CartPole-v1')"],"outputs":[],"execution_count":21,"metadata":{"id":"u9U6v6GPIyZ2","executionInfo":{"status":"ok","timestamp":1740656795105,"user_tz":-540,"elapsed":3,"user":{"displayName":"Ki-Baek Lee","userId":"00357310680332321506"}}}},{"cell_type":"markdown","source":["### 3. 에피소드 반복\n"],"metadata":{"id":"O_GYrwBMIyZ2"}},{"cell_type":"code","source":["for episode in range(10):  # 10개의 에피소드 실행\n","    observation = env.reset()  # 환경 초기화\n","    done = False  # 에피소드가 종료되었는지 여부를 나타내는 변수를 초기화\n","    total_reward = 0  # 에피소드 동안 얻은 총 보상을 초기화\n","\n","    while not done:  # 에피소드가 종료될 때까지 반복\n","        # 랜덤 행동 선택 (0: 왼쪽, 1: 오른쪽)\n","        action = env.action_space.sample()\n","\n","        # 선택한 행동을 환경에 적용하고 다음 상태, 보상, 에피소드 종료 여부, 추가 정보를 반환\n","        next_observation, reward, done, info = env.step(action)\n","\n","        total_reward += reward  # 에피소드 동안 얻은 보상을 누적\n","        observation = next_observation  # 다음 상태 업데이트\n","\n","        # 환경 렌더링 (주석 처리하면 렌더링을 비활성화)\n","        # env.render()\n","\n","    # 각 에피소드가 종료될 때 총 보상을 출력\n","    print(f\"Episode {episode + 1}: Total reward = {total_reward}\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["Episode 1: Total reward = 14.0\n","Episode 2: Total reward = 15.0\n","Episode 3: Total reward = 17.0\n","Episode 4: Total reward = 12.0\n","Episode 5: Total reward = 21.0\n","Episode 6: Total reward = 24.0\n","Episode 7: Total reward = 17.0\n","Episode 8: Total reward = 12.0\n","Episode 9: Total reward = 16.0\n","Episode 10: Total reward = 9.0\n"]}],"execution_count":22,"metadata":{"id":"kqiEwLOfIyZ2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740656796298,"user_tz":-540,"elapsed":4,"user":{"displayName":"Ki-Baek Lee","userId":"00357310680332321506"}},"outputId":"ccda3104-47ac-42bf-bd0c-ec7a824db8cf"}},{"cell_type":"markdown","source":["### 4. 환경 종료\n","* 모든 에피소드가 종료되면 환경을 종료"],"metadata":{"id":"jaiMsV-JIyZ2"}},{"cell_type":"code","source":["env.close()"],"outputs":[],"execution_count":23,"metadata":{"id":"dhhBkuv0IyZ2","executionInfo":{"status":"ok","timestamp":1740657122253,"user_tz":-540,"elapsed":1,"user":{"displayName":"Ki-Baek Lee","userId":"00357310680332321506"}}}}]}