{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOqYnNxzAiK+2KIB8mzTuOr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Fy2_q1yA_eY2"},"source":["# Recurrent Neural Network\n"]},{"cell_type":"markdown","metadata":{"id":"kFWSw3mPzCd3"},"source":["### Imports"]},{"cell_type":"code","metadata":{"id":"ePyjL-fEA4As","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733457712398,"user_tz":-540,"elapsed":9285,"user":{"displayName":"Ki-Baek Lee","userId":"00357310680332321506"}},"outputId":"bcac9e68-baa2-4bfd-c6ca-9f8e1976d949"},"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# for reproducibility\n","torch.manual_seed(100)\n"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x79192b2df150>"]},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"c-W8ykrC5Pz4"},"source":["### 1 Dataset Construction\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kh5IsVGt5ba4","executionInfo":{"status":"ok","timestamp":1638237894461,"user_tz":-540,"elapsed":265,"user":{"displayName":"Ki-Baek Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00357310680332321506"}},"outputId":"18d38a7e-ace8-43bb-8dfd-7bdedf3d9597"},"source":["# Dictionary\n","sample_sentence = 'hi!hello.'\n","char_set = list(set(sample_sentence))\n","dic = {c: i for i, c in enumerate(char_set)}\n","\n","# Parameters\n","dic_size = len(dic)\n","input_size = dic_size\n","hidden_size = dic_size\n","\n","# Dataset setting\n","x_batch = []\n","y_batch = []\n","\n","x_data = [dic[c] for c in sample_sentence[:-1]]\n","x_one_hot = [np.eye(dic_size)[x] for x in x_data]\n","y_data = [dic[c] for c in sample_sentence[1:]]\n","\n","x_batch.append(x_one_hot)\n","y_batch.append(y_data)\n","\n","# To torch tensors\n","X = torch.FloatTensor(x_batch)\n","Y = torch.LongTensor(y_batch)\n","print(X.shape)\n","print(Y.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 8, 7])\n","torch.Size([1, 8])\n"]}]},{"cell_type":"markdown","metadata":{"id":"SH2RX5pEBB0H"},"source":["### 2 RNN model\n","* Input (입력의 형태)\n","  + Input type: torch.Tensor\n","  + Input shape: (N x S x E)\n","    - N: Batch size, S: Sequence length, E: Embedding size\n","    - 단, **batch_first=True** 일 때\n","  + 입력값 'hi!hello'\n","    - (1, 8, 7)\n","* Hidden (출력의 형태)\n","  + Hidden type: torch.Tensor\n","  + 출력값 'i!hello.'\n","    - (1, 8, 7)"]},{"cell_type":"code","metadata":{"id":"WGu6jWggenAc"},"source":["# Model\n","learning_rate = 0.1\n","training_epochs = 50\n","model = nn.RNN(input_size, hidden_size, batch_first=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s6XeYPhI6Tig","executionInfo":{"status":"ok","timestamp":1636360166459,"user_tz":-540,"elapsed":3,"user":{"displayName":"Ki-Baek Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00357310680332321506"}},"outputId":"a17fe51d-b226-4adf-8b63-0e764c66cc0f"},"source":["# define cost/loss & optimizer\n","criterion = nn.CrossEntropyLoss()    # Softmax\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# train\n","for epoch in range(training_epochs):\n","  optimizer.zero_grad()\n","  outputs, _status = model(X)\n","  loss = criterion(outputs.reshape(-1, dic_size), Y.reshape(-1))\n","  loss.backward()\n","  optimizer.step()\n","  if epoch % 5 == 4:\n","    result = outputs.data.numpy().argmax(axis=2)\n","    result_str = ''.join([char_set[c] for c in np.squeeze(result)])\n","    print('epoch: ',epoch, 'loss: ', loss.item(), 'prediction: ', result_str, 'true Y: ', sample_sentence[1:])\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch:  4 loss:  1.2792741060256958 prediction:  i!hillo. true Y:  i!hello.\n","epoch:  9 loss:  0.9466097354888916 prediction:  i!hillo. true Y:  i!hello.\n","epoch:  14 loss:  0.8066588640213013 prediction:  i!hillo. true Y:  i!hello.\n","epoch:  19 loss:  0.7434771656990051 prediction:  i!hillo. true Y:  i!hello.\n","epoch:  24 loss:  0.712984561920166 prediction:  i!hillo. true Y:  i!hello.\n","epoch:  29 loss:  0.6942877769470215 prediction:  i!hillo. true Y:  i!hello.\n","epoch:  34 loss:  0.6845752596855164 prediction:  i!hillo. true Y:  i!hello.\n","epoch:  39 loss:  0.6790880560874939 prediction:  i!hillo. true Y:  i!hello.\n","epoch:  44 loss:  0.6758877635002136 prediction:  i!hillo. true Y:  i!hello.\n","epoch:  49 loss:  0.6733384132385254 prediction:  i!hillo. true Y:  i!hello.\n"]}]},{"cell_type":"markdown","metadata":{"id":"hc6TPzluWB1M"},"source":["### 3 Assignment\n","### 다음 3개의 문장을 batch data로 활용해 RNN을 학습해보자 (아래의 미완성 코드, 위 실습코드, 실행결과를 참고)\n","* 'howareyou'\n","* 'whats up?'\n","* 'iamgreat.'"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":108},"id":"klzzEMCU9SuA","executionInfo":{"status":"error","timestamp":1733457718158,"user_tz":-540,"elapsed":348,"user":{"displayName":"Ki-Baek Lee","userId":"00357310680332321506"}},"outputId":"e4a17f16-3018-41bc-d32e-04da8b601b89"},"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# for reproducibility\n","torch.manual_seed(100)\n","\n","# Dictionary\n","sample_sentences = ['howareyou', 'whats up?', 'iamgreat.']\n","char_set = list(set(''.join(sample_sentences)))\n","dic = {c: i for i, c in enumerate(char_set)}\n","\n","# Parameters\n","dic_size = len(dic)\n","input_size = dic_size\n","hidden_size = dic_size\n","\n","# Dataset setting\n","input_batch = []\n","target_batch = []\n","\n","for sentence in sample_sentences:\n","\n","\n","# To torch tensors\n","X = torch.FloatTensor(input_batch)\n","Y = torch.LongTensor(target_batch)\n","\n","# Model\n","learning_rate = 0.05\n","training_epochs = 500\n","model = nn.RNN(input_size, hidden_size, batch_first=True)\n","\n","# define cost/loss & optimizer\n","criterion = nn.CrossEntropyLoss()    # Softmax\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# train\n","for epoch in range(training_epochs):\n","\n","result = outputs.data.numpy().argmax(axis=2)\n","for sentence in result:\n","  print(''.join([char_set[c] for c in np.squeeze(sentence)]))\n"],"execution_count":2,"outputs":[{"output_type":"error","ename":"IndentationError","evalue":"expected an indented block after 'for' statement on line 23 (<ipython-input-2-52872d442488>, line 27)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-52872d442488>\"\u001b[0;36m, line \u001b[0;32m27\u001b[0m\n\u001b[0;31m    X = torch.FloatTensor(input_batch)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 23\n"]}]}]}