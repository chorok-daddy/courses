{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"L13_Linear_Regression.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPIuA3e7JMl0nLEuKQVjRSK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Fy2_q1yA_eY2"},"source":["# Linear Regression\n"," "]},{"cell_type":"markdown","metadata":{"id":"kFWSw3mPzCd3"},"source":["### Imports"]},{"cell_type":"code","metadata":{"id":"ePyjL-fEA4As","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633401241356,"user_tz":-540,"elapsed":31465,"user":{"displayName":"Ki-Baek Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00357310680332321506"}},"outputId":"c58d8f1b-a79e-4828-d849-1fa9859a0809"},"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as func\n","import torch.optim as opt\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Seed 고정\n","torch.manual_seed(1)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f7d89bf3070>"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"SH2RX5pEBB0H"},"source":["### 1 Data loading\n","| x | y |\n","|---|---|\n","| 1 | 1 |\n","| 2 | 2 |\n","| 3 | 3 |\n","\n"]},{"cell_type":"code","metadata":{"id":"HL2ZwVjWBCw7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633329831981,"user_tz":-540,"elapsed":276,"user":{"displayName":"Ki-Baek Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00357310680332321506"}},"outputId":"9949d3f0-c073-465c-ab91-317af5d99c45"},"source":["# Data 수동으로 입력하기\n","x_train = torch.FloatTensor([[1],[2],[3]])\n","y_train = torch.FloatTensor([[1],[2],[3]])\n","\n","print(x_train)\n","print(x_train.shape)\n","print(y_train)\n","print(y_train.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1.],\n","        [2.],\n","        [3.]])\n","torch.Size([3, 1])\n","tensor([[1.],\n","        [2.],\n","        [3.]])\n","torch.Size([3, 1])\n"]}]},{"cell_type":"markdown","metadata":{"id":"bfef_frYE6yz"},"source":["### 2 Hypothesis (가정) and Cost\n","$$ y_{hypo} = H(x) = w \\cdot x + b $$\n","* Linear(선형)임을 가정한 경우 위 수식을 만족해야한다\n","* data가 3개인 경우,\n","  $$\\begin{bmatrix} y_1 \\\\ y_2 \\\\ y_3 \\end{bmatrix} =  w \\cdot \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} + b $$\n","  + 이를 만족하는 $w$와 $b$를 구해야 한다 \n","* Cost function으로 Mean-Square-Error를 이용한다\n","$$ \\frac{1}{N} \\sum_{n=1}^{n=N} (y_{hypo, (n)} - y_{train, (n)})^2$$"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m_NA4ix0HdJw","executionInfo":{"status":"ok","timestamp":1633331626516,"user_tz":-540,"elapsed":238,"user":{"displayName":"Ki-Baek Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00357310680332321506"}},"outputId":"d47a206a-af7a-4e4b-a28e-84ea316cd3f4"},"source":["# Model 초기화 (입력 dim, 출력 dim)\n","model = nn.Linear(1, 1)\n","\n","# Hypothesis 정의\n","y_hypo = model(x_train)\n","print(list(model.parameters()))\n","print(y_hypo)\n","\n","# Cost(Mean Sqaure Error) 계산\n","cost = func.mse_loss(y_hypo, y_train)\n","print(cost)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Parameter containing:\n","tensor([[0.9812]], requires_grad=True), Parameter containing:\n","tensor([-0.4231], requires_grad=True)]\n","tensor([[0.5581],\n","        [1.5393],\n","        [2.5206]], grad_fn=<AddmmBackward>)\n","tensor(0.2124, grad_fn=<MseLossBackward>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"6xTxG_amCwbD"},"source":["### 3 Cost Optimization\n","* Optimizer로 stochastic gradient descent를 이용한다"]},{"cell_type":"code","metadata":{"id":"4nLfC1Ko2d9g"},"source":["# Optimizer 설정 (learning rate = 0.01로 설정)\n","optimizer = opt.SGD(model.parameters(), lr=0.01)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L1y0Pa_fC-sE","executionInfo":{"status":"ok","timestamp":1633327139712,"user_tz":-540,"elapsed":325,"user":{"displayName":"Ki-Baek Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00357310680332321506"}},"outputId":"704e96af-dfea-493c-9c14-c987f9b2cf1d"},"source":["# 반복\n","for epoch in range(1000):\n","\n","  # Cost 계산 / mse_loss(가정에의한값, 참값)\n","  y_hypo = model(x_train)\n","  cost = func.mse_loss(y_hypo, y_train)\n","\n","  # cost를 이용해 model update\n","  optimizer.zero_grad()\n","  cost.backward()\n","  optimizer.step()\n","\n","  # 100번 마다 중간결과 출력\n","  if epoch % 100 == 99:\n","    params = list(model.parameters())\n","    w = params[0].item()\n","    b = params[1].item()\n","    print('Epoch {:4d}/{} w: {:.3f} b: {:.3f} Cost: {:.6f}'.format(\n","        epoch+1, 1000, w, b, cost.item()\n","    ))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch  100/1000 w: 1.006 b: -0.014 Cost: 0.000026\n","Epoch  200/1000 w: 1.005 b: -0.011 Cost: 0.000016\n","Epoch  300/1000 w: 1.004 b: -0.008 Cost: 0.000010\n","Epoch  400/1000 w: 1.003 b: -0.007 Cost: 0.000006\n","Epoch  500/1000 w: 1.002 b: -0.005 Cost: 0.000004\n","Epoch  600/1000 w: 1.002 b: -0.004 Cost: 0.000002\n","Epoch  700/1000 w: 1.001 b: -0.003 Cost: 0.000001\n","Epoch  800/1000 w: 1.001 b: -0.003 Cost: 0.000001\n","Epoch  900/1000 w: 1.001 b: -0.002 Cost: 0.000001\n","Epoch 1000/1000 w: 1.001 b: -0.002 Cost: 0.000000\n"]}]},{"cell_type":"markdown","metadata":{"id":"zgw_2tAt4kh0"},"source":["### 4 Multivariable Linear Regression\n","$$ y_{hypo} = H(\\textbf{x}) = \\textbf{W} \\cdot \\textbf{x} + b $$\n","* Linear(선형)임을 가정한 경우 위 수식을 만족해야한다\n","  $$ y_{hypo} = \\begin{bmatrix} w_{1} && w_{2} && w_{3} \\end{bmatrix}  \\cdot \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} + \\begin{bmatrix} b \\end{bmatrix} $$\n","  + MSE cost를 최소화하는 $w$와 $b$를 구해야 한다 "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XMMgAjeh45kP","executionInfo":{"status":"ok","timestamp":1633401248692,"user_tz":-540,"elapsed":1643,"user":{"displayName":"Ki-Baek Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00357310680332321506"}},"outputId":"ce97516c-00bf-4b3d-9046-1d6c84058704"},"source":["# Numpy를 이용해 csv file을 ndarray로 가져오기\n","dataset = np.loadtxt(\n","    '/content/drive/MyDrive/Colab Notebooks/courses/AI_Appl/data_linear_regression.csv', \n","    delimiter=',', \n","    dtype=np.float32)\n","# 순서를 random으로 섞기\n","np.random.shuffle(dataset)\n","\n","# torch tensor로 변환\n","x_train = torch.FloatTensor(dataset[:,:-1])\n","y_train = torch.FloatTensor(dataset[:,[-1]])\n","\n","# Linear model\n","model = nn.Linear(3,1)\n","print(list(model.parameters()))\n","# Optimizer 설정\n","optimizer = opt.SGD(model.parameters(), lr=0.00001)\n","\n","# 반복\n","for epoch in range(1000):\n","  y_hypo = model(x_train)\n","  cost = func.mse_loss(y_hypo, y_train)\n","\n","  # model update\n","  optimizer.zero_grad()\n","  cost.backward()\n","  optimizer.step()\n","\n","  # 100번 마다 중간결과 출력\n","  if epoch % 100 == 99:\n","    print('Epoch {:4d}/{} Cost: {:.6f}'.format(epoch+1, 1000, cost.item()))\n","\n","print(y_hypo-y_train)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Parameter containing:\n","tensor([[ 0.2975, -0.2548, -0.1119]], requires_grad=True), Parameter containing:\n","tensor([0.2710], requires_grad=True)]\n","Epoch  100/1000 Cost: 15.271611\n","Epoch  200/1000 Cost: 14.740535\n","Epoch  300/1000 Cost: 14.242667\n","Epoch  400/1000 Cost: 13.775784\n","Epoch  500/1000 Cost: 13.337808\n","Epoch  600/1000 Cost: 12.926823\n","Epoch  700/1000 Cost: 12.541004\n","Epoch  800/1000 Cost: 12.178720\n","Epoch  900/1000 Cost: 11.838418\n","Epoch 1000/1000 Cost: 11.518639\n","tensor([[ 2.1901],\n","        [ 1.7932],\n","        [-9.6721],\n","        [-0.0190],\n","        [-1.1170],\n","        [-0.3340],\n","        [ 2.1892],\n","        [-3.1836],\n","        [ 1.1443],\n","        [ 0.3135],\n","        [ 4.1560],\n","        [ 0.3398],\n","        [ 1.6441],\n","        [ 3.6337],\n","        [ 4.9286],\n","        [-6.1586],\n","        [ 1.3795],\n","        [-6.1406],\n","        [-1.1264],\n","        [-3.2643],\n","        [ 2.1824],\n","        [ 3.9121],\n","        [ 0.3311],\n","        [ 0.6157],\n","        [ 1.0512]], grad_fn=<SubBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"hc6TPzluWB1M"},"source":["### 5 Assignment\n","* 행렬 방정식 풀기\n","  - 다음 행렬 방정식을 'Linear Regression'을 이용해 풀어보자\n","    + 적당한 learning rate를 찾아 1000 epoch 정도 계산해본다\n","    + 'Pseudo Inverse'를 이용한 풀이와 비교해본다\n","  - Hint: y = wx 꼴로 변환해본다\n","    + Ax=B에서는 x가 미지수이지만, y=wx에서는 w가 미지수임에 주의!\n","    + linear model에서 b를 없애기 위해서 nn.Linear() 사용법을 검색해보자 \n","$$Ax=B$$\n","$$A = \\begin{bmatrix}0 & 1 \\\\ 1 & 1 \\\\ 2 & 1 \\\\ 3 & 1 \\end{bmatrix} $$\n","$$B = \\begin{bmatrix}-1 \\\\ 0.2 \\\\ 0.9 \\\\ 2.1 \\end{bmatrix} $$"]}]}